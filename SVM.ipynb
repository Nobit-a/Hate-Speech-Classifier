{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "\tdef __init__(self):\n",
    "\t\tself.wnl = nltk.stem.WordNetLemmatizer()\n",
    "\tdef __call__(self, doc):\n",
    "\t\treturn [self.wnl.lemmatize(t) for t in nltk.word_tokenize(doc)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Windows/Desktop/NUS/Pyhton/Main.csv',encoding='latin1',keep_default_na=False);\n",
    "df = df[1:500];\n",
    "\n",
    "dfx = df['tweet'];\n",
    "dfy = df['class'];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 1.0\n",
      "Training Confusion = [[ 12   0   0]\n",
      " [  0 336   0]\n",
      " [  0   0  51]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        12\n",
      "          1       1.00      1.00      1.00       336\n",
      "          2       1.00      1.00      1.00        51\n",
      "\n",
      "avg / total       1.00      1.00      1.00       399\n",
      "\n",
      "========================================================\n",
      "Test Accuracy 0.94\n",
      "Test Confusion = [[ 0  0  0]\n",
      " [ 2 84  3]\n",
      " [ 0  1 10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         2\n",
      "          1       0.94      0.99      0.97        85\n",
      "          2       0.91      0.77      0.83        13\n",
      "\n",
      "avg / total       0.92      0.94      0.93       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dfx, dfy, train_size = 0.8, test_size = 0.2, random_state = random.randrange(99999), shuffle = True)\n",
    "\n",
    "cv = CountVectorizer(tokenizer=LemmaTokenizer(), stop_words=stop_words, binary=True)\n",
    "cv_matrix_train = cv.fit_transform(x_train)\n",
    "vocab = cv.get_feature_names()\n",
    "cv_matrix_train = cv_matrix_train.toarray()\n",
    "cv_matrix_test =  cv.transform(x_test)\n",
    "clf = LinearSVC();\n",
    "clf.fit(cv_matrix_train, y_train);\n",
    "y_pred_train = clf.predict(cv_matrix_train)\n",
    "y_pred_test = clf.predict(cv_matrix_test)\n",
    "print('Training Accuracy {}'.format(clf.score(cv_matrix_train, y_train)))\n",
    "print('Training Confusion = {}'.format(metrics.confusion_matrix(y_pred_train, y_train)))\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print('========================================================')\n",
    "print('Test Accuracy {}'.format(clf.score(cv_matrix_test, y_test)))\n",
    "print('Test Confusion = {}'.format(metrics.confusion_matrix(y_pred_test, y_test)))\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
